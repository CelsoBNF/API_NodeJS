# API_NodeJS
Development of an API with a crawler for data extraction through the Github website. 
After crawler runs through the API, it inserts the parameters that were embedded in 
the API route and inserts it into the Github search fieldand thus extracts all the
data. After extracting the data, the crawler saves the responses of the requests in
a "MySQL" relational database and crawler execution responses to a non-relational 
database "mongoDB" in JSON format.
